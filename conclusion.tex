\section{Conclusion}
\label{sec:conclusion}

% days of manually constructing features from data are almost over. The machines will win
\subsection{Applicability of Anomaly Detection Methods}

\subsection{Experimental extensions }

It would be of interest to expand upon the work done overloading an ungeared motor, specifically applying a rotary encoder and an ammeter. This was the initial plan, however the experimental set up rapidly became overcomplicated, meaning it was impractical to take both contact microphone data and rotary encoder data. The revolution speed given by the rotary encoder, coupled with an ammeter in series with the motor, would allow insight into how the speed of the shaft varies with the current drawn and the corresponding vibrations produced. This could reveal more about slipping produced during load application and any momentary losses of power due to this. 


%add here about power supply limitations at load in water



\addcontentsline{toc}{section}{Acknowledgements}
\section*{Acknowledgements}

\small We thank Dr. Chris Saunter, our consultant for this project. We also thank Prof. Paula Chadwick for the Team Project Module. Many thanks to Owen Jones and Carl Tipton from Tracerco who are reponsible for this project idea. We appreciate the help of the Physics department technicians, Paul Foley and Ryan Ellison.




















































\iffalse
We proposed a new algorithm, \emph{EXPoSE}, to perform anomaly detection on very large-scale datasets and streams with concept drift. Although anomaly detection is a problem of central importance in many applications, only a few algorithms are scalable to the vast amount of data we are often confronted with.

The EXPoSE anomaly detection classifier calculates a score (the likelihood of a query point belonging to the class of normal data) using the inner product between a feature map and the kernel embedding of probability measures. The kernel embedding technique provides an efficient way to work with probability measures without the necessity to make assumptions about the underlying distributions.

Despite its simplicity EXPoSE obeys a \emph{linear} computational complexity for learning and can make predictions in \emph{constant} time while it requires only  \emph{constant} memory. 
When applied incrementally or online, a model update can also be performed in \emph{constant} time. We demonstrated that EXPoSE can be used as an efficient anomaly detection algorithm with the same predictive performance as the best state of the art methods while being significant faster than techniques with the same discriminant power.\cite{Habel_2007_IAG}
\fi